{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DataCooker Documentation","text":"<p>DataCooker is a small recipe engine for biomolecular data. You describe what you want to build (targets) and how to compute them (instructions), and DataCooker resolves dependencies, executes steps, and keeps intermediate results in a cache. The repository also ships ready-made pipelines for A3M/FASTA parsing, mmCIF/CCD processing, LMDB packaging, and graph splits used by downstream training jobs.</p>"},{"location":"#why-datacooker","title":"Why DataCooker","text":"<ul> <li>Composable recipe DSL with typed targets and explicit inputs</li> <li>Deterministic dependency resolution with a pluggable <code>ParsingCache</code></li> <li>Batteries included biomolecular pipelines (A3M, CIF/CCD, LMDB, graph splits)</li> <li>Small surface area: one <code>RecipeBook</code>, one <code>Cooker</code>, optional helper <code>parse</code>/<code>rebuild</code></li> </ul>"},{"location":"#quick-start-custom-recipe","title":"Quick start (custom recipe)","text":"<pre><code>from datacooker import ParsingCache, RecipeBook, Cooker\n\n# Define a tiny two-step recipe\nbook = RecipeBook()\nbook.add(\n    targets=((\"clean_text\", str),),\n    instruction=lambda raw: raw.strip().upper(),\n    inputs={\"args\": ((\"raw_text\", str),)},\n)\nbook.add(\n    targets=((\"length\", int),),\n    instruction=lambda text: len(text),\n    inputs={\"args\": ((\"clean_text\", str),)},\n)\n\ncache = ParsingCache()\ncooker = Cooker(cache, book)\ncooker.prep({\"raw_text\": \"  ACDEfg  \"})\ncooker.cook()\nprint(cooker.serve([\"clean_text\", \"length\"]))\n# {'clean_text': 'ACDEFG', 'length': 6}, ['clean_text', 'length']\n</code></pre>"},{"location":"#pick-an-existing-pipeline","title":"Pick an existing pipeline","text":"<ul> <li><code>pipelines/recipe/a3m_recipe_book.py</code>: parse A3M/FASTA alignments into biomol feature containers</li> <li><code>pipelines/recipe/cif_recipe_book.py</code>, <code>pipelines/recipe/ccd_recipe_book.py</code>: mmCIF/CCD extraction</li> <li><code>pipelines/recipe/graph_lmdb.py</code>, <code>pipelines/recipe/graph_lmdb_from_attached.py</code>: build LMDBs for graph data</li> <li><code>pipelines/recipe/train_valid_graph_split.py</code>: split graphs into train/valid with basic stats</li> </ul> <p>Use the helper API to run a pipeline: <pre><code>from pathlib import Path\nfrom datacooker.core import parse\nfrom pipelines.utils.convert import load_cif  # example loader\n\nrecipe_path = Path(\"pipelines/recipe/train_valid_graph_split.py\")\nresults = parse(\n    recipe_path=recipe_path,\n    file_path=Path(\"data/edges.tsv\"),\n    load_func=load_cif,\n    transform_func=None,\n    targets=[\"train_edge_list\", \"valid_edge_list\"],\n)\n</code></pre></p>"},{"location":"#where-to-go-next","title":"Where to go next","text":"<ul> <li>Getting started: install and run a first recipe</li> <li>Concepts &amp; architecture: how recipes, targets, and the cache fit together</li> <li>Pipelines: what is packaged in <code>pipelines/</code></li> <li>API reference: the <code>datacooker</code> Python API surface</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section documents the public surface of <code>datacooker</code>. Module paths are relative to <code>src/datacooker</code>.</p>"},{"location":"api/#corepy","title":"<code>core.py</code>","text":"<ul> <li><code>ParsingCache(key_transform: Callable[[str], tuple[str, ...]] | None = None)</code>: nested, transformable key-value store for intermediate data. Methods:</li> <li><code>add_data(name, data)</code>: insert if not already present.</li> <li><code>__contains__(name)</code>: membership check.</li> <li><code>__getitem__(name)</code>: retrieve stored value.</li> <li><code>keys()</code>: flattened list of stored keys.</li> <li><code>RecipeBook</code>: builder for ordered recipe steps.</li> <li><code>add(targets, instruction, inputs)</code>: register a step. <code>targets</code> can be a tuple of <code>(name, type)</code> pairs or a list of such tuples. <code>inputs</code> supports <code>args</code>, <code>kwargs</code>, and static <code>params</code>.</li> <li><code>__contains__(target_name)</code>: whether a target is defined.</li> <li><code>__getitem__(target_name)</code>: retrieve the <code>Recipe</code> for a given target.</li> <li><code>targets()</code>: list declared targets.</li> <li><code>Cooker(parse_cache, recipebook, targets=None)</code>: orchestrator.</li> <li><code>prep(data_dict, fields=None)</code>: seed the cache.</li> <li><code>cook()</code>: execute all targets in dependency order.</li> <li><code>serve(targets=None)</code>: return selected targets (or defaults from the recipe book).</li> <li><code>parse(recipe_path, file_path, load_func, transform_func=None, targets=None, **extra_kwargs)</code>: helper to load a file, run the recipe on it, and return results.</li> <li><code>rebuild(recipe_path, datadict, transform_func=None, targets=None, **extra_kwargs)</code>: same as <code>parse</code> but starts from an existing <code>datadict</code>.</li> </ul>"},{"location":"api/#recipepy","title":"<code>recipe.py</code>","text":"<ul> <li><code>Variable(name, type)</code>: typed target definition.</li> <li><code>Inputs(args=(), kwargs={}, params={})</code>: inputs container used inside <code>Recipe</code>.</li> <li><code>Recipe(targets, instruction, inputs)</code>: immutable step description.</li> <li><code>RecipeError</code>: raised when a target is missing.</li> </ul>"},{"location":"api/#patterns","title":"Patterns","text":"<ul> <li>Optional targets: declare a target type as <code>type | None</code> so the cooker returns <code>None</code> when missing instead of raising.</li> <li>Wildcard args: include glob characters (e.g., <code>\"input_*\"</code>) in <code>args</code> to gather all matching cache entries.</li> <li>Multiple outputs: when a step defines multiple targets, the instruction must return a tuple with the same arity.</li> </ul>"},{"location":"concepts/","title":"Concepts &amp; Architecture","text":""},{"location":"concepts/#core-pieces","title":"Core pieces","text":"<ul> <li><code>RecipeBook</code>: ordered collection of steps. Each step declares <code>targets</code>, an <code>instruction</code> callable, and <code>inputs</code> that point to other targets (args/kwargs) plus static <code>params</code>.</li> <li><code>ParsingCache</code>: a keyed store for intermediate and final values. It can flatten keys (<code>foo.bar</code>) or apply a custom <code>key_transform</code> for nested access.</li> <li><code>Cooker</code>: orchestrates execution. It resolves dependencies, handles wildcard inputs (glob patterns like <code>input*</code>), detects cycles, runs instructions, and stores outputs back into the cache.</li> <li>Helpers: <code>parse()</code> loads an input file, seeds the cache, runs a recipe book from disk, and returns selected targets. <code>rebuild()</code> is similar but starts from an in-memory <code>datadict</code>.</li> </ul>"},{"location":"concepts/#execution-model","title":"Execution model","text":"<ol> <li>Prep: seed the cache with initial fields via <code>cooker.prep(data_dict)</code>.</li> <li>Resolve: for each requested target, resolve all upstream inputs:</li> <li>Args/kwargs in <code>Inputs</code> are mapped by name to other targets.</li> <li>Wildcard args are expanded against existing cache keys.</li> <li>Optional targets (<code>type | None</code>) return <code>None</code> if not declared.</li> <li>Cook: run instructions in dependency order, caching outputs as they are produced.</li> <li>Serve: retrieve specific targets or all defaults defined by the recipe book.</li> </ol>"},{"location":"concepts/#declaring-steps","title":"Declaring steps","text":"<pre><code>from datacooker import RecipeBook\n\nbook = RecipeBook()\nbook.add(\n    targets=((\"features\", dict),),\n    instruction=lambda seq: {\"len\": len(seq)},\n    inputs={\"args\": ((\"sequence\", str),)},\n)\nbook.add(\n    targets=((\"summary\", str),),\n    instruction=lambda feats: f\"length={feats['len']}\",\n    inputs={\"args\": ((\"features\", dict),)},\n)\n</code></pre>"},{"location":"concepts/#working-with-files-vs-memory","title":"Working with files vs memory","text":"<ul> <li>Use <code>datacooker.core.parse()</code> when your starting point is a file path and you have a loader function that returns a data dictionary.</li> <li>Use <code>datacooker.core.rebuild()</code> when you already have a populated <code>datadict</code> (e.g., from a previous pipeline stage or cached LMDB read).</li> </ul>"},{"location":"concepts/#error-handling","title":"Error handling","text":"<ul> <li>Cycles raise <code>RuntimeError</code>.</li> <li>Missing targets raise <code>RecipeError</code>.</li> <li>Type mismatches in returned tuples raise <code>ValueError</code> with expected target counts.</li> <li>Duplicate targets in a recipe book raise <code>ValueError</code>.</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#install","title":"Install","text":"<ul> <li>Python 3.10+ is required.</li> <li>Development install (recommended while writing recipes):   <pre><code>pip install -e .\n</code></pre></li> <li>If you use <code>pixi</code>, the repo already ships a lockfile:   <pre><code>pixi install\npixi shell\n</code></pre></li> </ul>"},{"location":"getting-started/#quick-smoke-test","title":"Quick smoke test","text":"<p>Run a minimal recipe to confirm the engine works: <pre><code>python - &lt;&lt;'PY'\nfrom datacooker import ParsingCache, RecipeBook, Cooker\nbook = RecipeBook()\nbook.add(targets=((\"x\", int),), instruction=lambda: 1, inputs={})\ncache = ParsingCache()\ncooker = Cooker(cache, book)\ncooker.prep({})\ncooker.cook()\nprint(\"x =\", cooker.serve([\"x\"]))\nPY\n</code></pre></p>"},{"location":"getting-started/#project-layout","title":"Project layout","text":"<ul> <li><code>src/datacooker</code>: core engine (<code>Cooker</code>, <code>RecipeBook</code>, <code>ParsingCache</code>, helpers)</li> <li><code>pipelines/recipe</code>: reusable recipe books (A3M/FASTA, mmCIF/CCD, LMDB builders, graph splits)</li> <li><code>pipelines/instructions</code>: atomic instruction functions used by the recipe books</li> <li><code>pipelines/utils</code> and <code>pipelines/transforms</code>: shared helpers for conversion and transforms</li> <li><code>configs</code>: Hydra/OmegaConf configs for pipeline runs</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next steps","text":"<ul> <li>Try an existing recipe book, e.g. <code>pipelines/recipe/a3m_recipe_book.py</code></li> <li>Customize a recipe by swapping instructions or adding new targets</li> <li>See Concepts for how dependency resolution works</li> </ul>"},{"location":"pipelines/","title":"Pipelines &amp; Recipes","text":"<p>The repository ships several recipe books under <code>pipelines/recipe</code>. Each book bundles instructions from <code>pipelines/instructions</code> into an executable workflow.</p>"},{"location":"pipelines/#data-parsing","title":"Data parsing","text":"<ul> <li><code>a3m_recipe_book.py</code>: parse A3M/FASTA alignments (headers + sequences) into biomol feature containers; see <code>pipelines/instructions/a3m_instructions.py</code>.</li> <li><code>cif_recipe_book.py</code>: mmCIF structure parsing with biomol features; uses helpers in <code>pipelines/instructions/cif_instructions.py</code>.</li> <li><code>ccd_recipe_book.py</code>: ingest CCD (chemical component dictionary) records.</li> <li><code>extract_fasta.py</code>: extract FASTA from alignment/sequence sources.</li> </ul>"},{"location":"pipelines/#packaging-and-metadata","title":"Packaging and metadata","text":"<ul> <li><code>filter_a3m_lmdb.py</code>: filter A3M datasets and store them in LMDB.</li> <li><code>build_seq_hash_map.py</code>: build hash maps for sequence deduplication.</li> <li><code>build_metadata.py</code>, <code>load_metadata.py</code>: enrich and load dataset metadata.</li> <li><code>build_af3_training.py</code>: assemble inputs for AF3 training.</li> </ul>"},{"location":"pipelines/#graph-pipelines","title":"Graph pipelines","text":"<ul> <li><code>graph_lmdb.py</code>, <code>graph_lmdb_from_attached.py</code>: convert graph-like biomolecular data into LMDB shards.</li> <li><code>seq_cluster.py</code>: build sequence clusters.</li> <li><code>train_valid_graph_split.py</code>: construct whole graphs, split them, extract edge lists, and compute edge statistics.</li> </ul>"},{"location":"pipelines/#running-a-recipe-book","title":"Running a recipe book","text":"<pre><code>from pathlib import Path\nfrom datacooker.core import parse\nfrom pipelines.utils.convert import load_cif  # loader -&gt; dict[str, Any]\n\nresults = parse(\n    recipe_path=Path(\"pipelines/recipe/cif_recipe_book.py\"),\n    file_path=Path(\"data/example.cif\"),\n    load_func=load_cif,\n    targets=[\"structure_container\"],  # or None for all\n)\n</code></pre>"},{"location":"pipelines/#customizing","title":"Customizing","text":"<ul> <li>Swap instruction functions to change preprocessing.</li> <li>Add targets with <code>RecipeBook.add()</code> to attach more derived signals.</li> <li>Use wildcard args when a step should consume multiple cached keys (e.g., <code>\"chain_*\"</code>).</li> </ul>"}]}